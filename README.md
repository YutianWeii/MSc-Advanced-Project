# MSc-Advanced-Project
## Introduction
### AI Audience, Please Come In ü§ñÔ∏èü§ñÔ∏èü§ñÔ∏è
In the context of post-humanism challenging anthropocentrism and the rapid development of AI art, the art world still lacks artworks created from non-human perspectives. Therefore, I aimed to regard AI as an audience rather than a tool, believing that an AI's dataset and model architecture constitute its "cognition." Through artistic experimentation, I designed an AI artist based on the Stable Diffusion model and three AI audiences based on the CLIP and GPT models but trained on different datasets, and completed the AI artwork "AI Audience, Please Come In" through their interaction. This work represents a new artistic experiment from AI to AI, reflecting the individuality of AI under new concepts and the broader possibilities of AI art, while also expressing the desire to treat non-human subjects equally.

### üé¨ Video: https://youtu.be/H2O9SunuKBY?si=hj6GO8Pgn_o4fkHI

<img src = "https://github.com/YutianWeii/jpg/blob/main/1.png" width = "800px">

## My Blog
### June 2023
üìÖ In the first week, I determined the project theme and established contact with my supervisor, Adam Cole. I scheduled our first meeting with Adam and prepared for it. Here is the initial project concept I wrote:
I want to continue researching "AI as an Art Audience" based on my previous paper. If you're interested, please visit: https://www.dropbox.com/s/45cheoq7m0bvucc/Final%20essay-Yutian%20Wei.pdf?dl=0
From a Post-humanist perspective, the line between non-human and human is blurred. However, most artworks today are created for human viewers. I believe considering non-human entities as art audiences will bring new possibilities, elevating AI from a tool to a viewer itself. I have two ideas now: 1.Making AI respond to artworks through code, potentially involving the differences in how different AI models perceive things. 2.Presenting the content that AI could potentially "see" to humans. This allows humans to experience art from the AI's perspective, leading to unconventional reflections on their relationship. The artwork may involve a combination of AI algorithms, VR, and other techniques.

üìÖ In the second week, I chose art experimentation as my research methodology, primarily focusing on the different cognition between AI and human beings. The artwork might take the form of an interactive installation:
1. Making AI respond to artworks through code, potentially exploring how different AI models perceive things differently.
2.Presenting the content that AI could "see" to humans, allowing them to experience art from the AI's perspective, leading to unconventional reflections on their relationship.
I believe that human understanding of AI is likely one-sided, and I cannot truly approach their way of thinking. On the technical side, I researched t-SNE (https://lvdmaaten.github.io/tsne/). I also referred to the art piece Bec0m1ng (https://www.posthumanart.com/post/bec0m1ng-a-speculative-exploration-of-ai-beyond-cognition-and-towards-presence), which consists of a digital environment with a fixed amount of matter and a group of AI agents.

üìÖ In the third week, I met with Adam to discuss my ideas. He advised me to consider specific research questions and recommended related artworks AICCA (https://hypebeast.com/2023/6/aicca-robotic-dog-mario-klingemann-coleccion-solo) and the scholar Joanna (https://www.kcl.ac.uk/people/joanna-zylinska, https://www.youtube.com/watch?v=jASV6Hjd2bY). We also discussed what genres of art AI audiences would view. Lastly, I read the submission requirements for the graduation project.

üìÖ In the fourth week, I read articles written by Joanna and watched videos. Here are the key terms I wrote during my thought process:
AI Aesthetics, evaluating the quality of artworks
Objective: Humans should treat AI equally and broaden their perspectives
Art from the AI's point of view or AI's response to art
Presenting art through the AI's eyes (the process)
An AI system's "cognition" is entirely dependent on its programming and training data, and they can only perform well in specific tasks.
Most current ML artworks use AI as a tool for artistic effects. I aim to make AI both the subject and purpose of art, creating artworks for AI. However, AI may not truly appreciate art; my goal is for the audience to treat non-human entities equally and include them as service recipients rather than just as tools.
How to transform artworks into a form that AI can appreciate?
AI sees the form but not the content
I make artworks for AI, AI makes artworks for itself
One-dimensional: sound, sequence; Two-dimensional: image; Three-dimensional: space; Multi-dimensional
Through AI, we can uncover hidden structures in one-dimensional data, then display and analyze these structures in higher-dimensional spaces.
AI's shared language: https://www.theatlantic.com/technology/archive/2017/06/what-an-ais-non-human-language-actually-looks-like/530934/, https://thenewstack.io/ai-bots-create-language-communicate/

Questions:
What aspects of artworks can AI appreciate? Form/Pattern/Meaning/Emotion/Similarity.
What forms can AI perceive? Digital/High-dimensional structures/Hidden information.
Is AI viewing art generated by AI or by humans?
How can artworks be transformed into a form that AI can appreciate?
In my work, should I borrow and transform famous artworks or create new pieces for transformation?
Will the visible form of artworks differ for different AI models?
Meaningless images‚Äîrevealed through AI algorithm processing.
What are non-human made AIs like, such as crows?
What type of artworks attract AI the most? Those with strong contrasts, sequences, specific frequencies, highly regular or irregular patterns.
Is the AI's generation process also a viewing process?

https://genekogan.com/works/color-of-words/

Gaussian images + steganography‚Äîonly AI can discern the information, reversing the process of ML art.
[https://en.wikipedia.org/wiki/Self-organizing_map]
(Text or image information hidden in pictures through technology, undetectable by humans) Inputting AI-processed images to obtain information.
[https://github.com/genekogan/ofxSelfOrganizingMap]

High-dimensional spaces, t-SNE.
[https://experiments.withgoogle.com/curator-table]
[https://mlart.co/?page=1&search=t-SNE]

AI's aesthetic assessment relies on datasets, which may lead to biases.
The visual presentation and textual description of an artwork, when separately analyzed and understood by AI, could result in significantly different interpretations (the division in understanding the artwork and the description).


### July 2023
üìÖ In the first week of July, I had my second meeting with Adam. Here is the outline of my report: 
Research question: Exploring the presentation forms of artworks when AI acts as an art audience.
Research methodology: Art experiments.
From the perspective of the form of artwork presentation:
1„ÄÅHow to transform artworks into a form that AI can understand?
2„ÄÅExperiment with creating art in the forms of images, text, and music that only AI can understand. They are meaningless in human world but meaningful in AI world.

From the perspective of AI's feedback results: 
1„ÄÅWhat type of work attracts AI the most? Those with high contrast, sequential, specific frequencies, highly regular or irregular ones? different with human preference. 
2„ÄÅAI‚Äôs aesthetic evaluation depends on datasets, which may lead to biases. 
3„ÄÅFor an artwork's visual presentation and textual description, separate analyses and understanding by AI might lead to vastly different results. For AI, perhaps words are more specific and easier to understand? 
4„ÄÅDoes AI understand human-created art and AI-generated art differently? Extended thinking: Could AI potentially create art for itself?
Relevant work: Color of Words (https://genekogan.com/works/color-of-words/)
Technical references: t-SNE: https://mlart.co/?page=1&search=t-SNE, https://distill.pub/2016/misread-tsne/

Adam recommended the work Botto (https://www.botto.com/) and the books Ways of Being (https://jamesbridle.com/books/ways-of-being/) and AI Art (http://www.openhumanitiespress.org/books/titles/ai-art/). He suggested I frame my thesis question as, "How can novel forms of artistic presentation help humans understand AI, with AI as the audience?" Technically, he advised me to try GANs, Autoencoders, and Diffusion models, and perhaps print out the latent space from the Diffusion models.

üìÖ The second week I went on a trip. üõ´

üìÖ In the third week, I read the book AI Art: Machine Visions and Warped Dreams. Here are some excerpts from my reading:

Does art exist outside the clearly designated realm of human cultural practice? Will ai create new conditions and new audiences for art? What will art ‚Äòafter‚Äô ai look like? Who will be its recipient?
Questions of originality and of the genius of an individual producer are hence framed by a study of the wider context that produces conditions for the emergence of a particular art form ‚Äì and that produces particular audiences which can identify, interpret and engage with that art form. These questions are therefore framed through what Michel Foucault has called an ‚Äòauthor function‚Äô (1992, 306): a wider discursive arrangement that stabilises into what a given cultural moment perceives as an ‚Äòauthor‚Äô or ‚Äòartist‚Äô.
call ‚Äòai imitation work‚Äô, also known as ‚Äòstyle transfer‚Äô. This mode of artistic production departs from the classical conceptualisation of art in terms of mimesis, i.e. the imitation of nature and its representation. For aristotle, all art was mimetic, but mimesis, proceeding by addition and not just repetition, involved what we would today call a ‚Äòremediation‚Äô (Bolter and Grusin 2002) of nature. it was thus a form of creative engagement, although one that was not yet linked to the humanist notions of originality and genius. Unlike mimesis, ‚Äòstyle transfer‚Äô is pure mimicry: a belaboured resemblance which is also a masquerade. in the context of the ai industry, where much of this kind of mimicry art is being produced, we need to ask: what underpins those efforts and what is it they actually attempt to masquerade as?
The ‚Äòcomputer‚Äô, be it in the shape of a data-processing machine, a robot or an algorithm, is only seen here as an imperfect approximation of such a human. But, in light of the argument laid out here, we should rather be asking, after Flusser, whether the human can actually be creative, or, more precisely: in what way can the human be creative?
‚Ä¶‚Ä¶

üìÖ In the fourth week, I continued reading books and literature. Here are some excerpts from my reading:

Dukaj goes so far as to suggest that, in the times of ai, human life is the only auratic form of art left to us, especially the way it escapes the digital record- ing and preprogrammed behaviour. he is not talking here about some unmediated encounter between two humans outside the technological setup or evoking similar humanist fantasies. it is the YouTube stars, pub- licising their lives and the branded products that shape them, that are for him the last artists of today, turn- ing lifestyle into an aesthetic experience while also externalising the knowledge about what it means to be human, and to behave like a human being, into the globally interconnected computer network. 
This form of art enforces what Berardi has described as ‚Äòmental subsumption‚Äô (2017), whereby the automation of vision and of cognitive activity paves the way for the emergence of constantly stimulated yet passive subjectivity. it thus ultimately works in the service of neoliberal- ism, a mutated form of capitalism that, according to Byungchul han, ‚Äòhas discovered the psyche as a productive force‚Äô. Yet what gets produced here is ‚Äòmental optimisation‚Äô (han 2017), for which Big data, algorithms and ai serve as perfect conduits. han calls this state of events a psychopolitics, which is his variation on Foucault‚Äôs notion of biopolitics, whereby the subject mobilises technologies of the self not to create any forms of freedom but rather to succumb, ‚Äòwillingly ‚Äì and even passionately‚Äô (2017), to auto-exploitation (fig. 9)

seeing like a Machine, Telling like a human

What is new about the FereT images is that they are not aimed at human eyes: as a training set for a facial recognition algorithm, their goal is to establish this commonality-in-difference for machine vision. indeed, these images are not meant to be seen at all by humans but are rather going inside the black box that ai has become. The fact that most ai research has been funded by the military, with darpa, the original funders of internet development, also sponsoring ‚Äòmore ai research than private corporations and any other branch of the government‚Äô (Barrat 2013, 180) 
‚Ä¶‚Ä¶


### August 2023
üìÖ In the first week, I read books and literature. Here are some excerpts from my reading:

From ‚ÄòApple‚Äô to ‚ÄòAnomaly‚Äô can thus be positioned as one of the seeing machines analysed elsewhere by the artist ‚Äì not because it sees anything by itself or even approximates the way machines see, but rather because ‚Äòmachines become autonomous systems that intervene and are coercive in the world‚Äô (clark 2019). it thus symbolises a larger infrastructure of perception and cognition which is currently being constructed at different scales ‚Äì and which, arguably, will soon change our ways of being in the world, as individuals and as citizens.

For me, the concept of ‚Äònonhuman photography‚Äô refers to photo- graphs that are not of, by or for the human (see Zylinska 2017, 5), encompassing images as diverse as depopulated vistas, satellite pictures and Qr codes. even though the opening premise of Nonhuman Photography is that today, in the age of ccTV, drone media, medical body scans and satellite imaging, photography has become increasingly decoupled from human agency and human vision, i have also suggested that even those images that have been taken by the human entail a nonhuman element.

William henry Fox Talbot‚Äôs Lace from The Pencil of Nature, 1845 ‚Äì an image that arguably hints at photog- raphy‚Äôs quintessentially algorithmic, pattern-based legacy (Batchen 2001, 169; Zylinska 2017, 182) ‚Äì remedi- ated by Joanna Zylinska via Google‚Äôs deepdream, 2018.

Novitskova took this spirit to her project, If Only You Could See What I‚Äôve Seen with Your Eyes (fig. 13)
Novitskova‚Äôs work offers a pre-monition of the world to come, a world in which not only the majority of images are not being taken with a human viewer in mind ‚Äì an issue that preoccupies Trevor paglen too ‚Äì but also one in which machines constantly perceive, communicate with and exist for other machines. Lykkeberg describes Novitskova‚Äôs project as looking as if it had been ‚Äòmade by and for who‚Äôs next‚Äô (40). We could therefore perhaps suggest that, draw- ing on nonhuman databases and modes of perception, Novitskova creates work for an artificial intelligence which is not here yet, inviting a speculation on the future of different species. This is ai read as another intelligence. in this context, her extinction diagrams copied from the internet gain a new dimension ‚Äì and a new audience.

Yet many of the more interesting works, amongst which i locate novitskova‚Äôs project, do attempt to enact a defamiliarisation of not just ‚Äòthe environment‚Äô (by showing it as damaged, disappear- ing or already gone) but also of us humans as recipients

Intelligent work on artificial intelligence could therefore perhaps attempt to sever that link between the work of art and human vision, going beyond the mere aesthesis of human experience to open up the problem of the universe itself as sentient. ‚Äòit is not the case that we begin life as observing, representing beings who then become through receptivity. rather, in the beginning is a dynamic and world-oriented receptivity from which organised cognition, and the sense of the self as subject or man emerges. it is from a primary open- ness to the world, a primarily sensed world, that there emerges the sense of one who sees‚Äô (colebrook 2014, 20)
‚Ä¶‚Ä¶

üìÖ In the second week, I continued reading books and literature. Here are some excerpts from my reading:

"Our understanding of AI is shaped by commercial interests; they instill fear of AI in us to protect their profits. This book aims to change this mindset. One way to alter the essence of these relationships is to change how we think about intelligence: what it is, how it functions in the world, and who possesses it. Beyond the narrow frameworks offered by tech companies and the doctrine of human uniqueness (the idea that human intelligence is singular and superior among all beings), there lies an entire realm of different ways of thinking and being intelligent. The task of this book is to reimagine: to look beyond ourselves and our own creations, to glimpse other or many different kinds of intelligence that have always been here, right in front of us ‚Äì in many cases, before us. By doing so, we might change our way of thinking about the world, thereby paving the way for a future that is less extractive, destructive, and unequal, and more just, kind, and regenerative."

"In recent decades, a very different imagination of intelligence has been underway. On one hand, from the biological and behavioral sciences; on the other, from a growing appreciation and integration of indigenous and non-Western knowledge systems, this new way of understanding intelligence runs counter to the narratives of singularity and greed. More importantly, for our story, it challenges the notion that intelligence is unique and even particularly 'human.'"

Establishing new relationships with non-human intelligence.

The Turing Test defines AI as that which can imitate humans, but should we confront AI and grant it rights? Human judgments of intelligence are based on human standards. The mirror test. 
Science is understanding a human-centered world in a human-centered way.

üìÖ In the third week, I continued reading books and literature. Here are some excerpts from my reading:

Somewhere between these two extremes ‚Äì between the plant pot and the continental forest, between the microchip and the satellite ‚Äì lies our actual lived experience, the place where our shared umwelts meet and mingle. For surely, as much as we differ, there must be points of overlap in our awareness, our sense of the world, which provide an opening to understanding. This turned out to be the case with my self-driving car; it was what Barbara Smuts discovered with the baboons. To understand a little of what plants mean and why they matter, we must discover what we have in common: the ways in which we share a world.
One way we might do this is to ask what plants hear. This simple question is already rife with contestation ‚Äì plants have no ears or other known receptors for sound waves. And yet, quite assuredly, they hear, as we shall prove. How they do so, what they do with that information, and what it means for our interrelationships are similar questions to those we ask ourselves about animal intelligence: how are we changed by encountering non-human senses and a non-human impression of the world?‚Äù
‚Ä¶‚Ä¶

üìÖ In the fourth week, I was in the midst of moving üè†.


### September 2023
üìÖ Week 1 Thought Fragments üß©:
Artists create concepts, but what do robots view? Emotions?

How to resist unconscious combinations?

AI as an extension of humans.

Text segmentation extends infinitely, while images highlight features and pixels.

Humans creating art for AI without using AI.

Art for AI viewing and the world through AI‚Äôs eyes (serving humans) are two distinct concepts.

Steganography: hiding information in artworks, like two identical images seen differently by AI.

Artwork references: https://www.fluate.net/en/travaux/vectoglyph, http://guillaumeslizewicz.com/posts/2020/i_can_remember/, https://www.aiartonline.com/design/masaru-mizuochi/

üìÖ Week 2: Went on a trip üõ´

üìÖ Week 3: I planned to present artworks as seen by AI, experimenting with the Stable Diffusion model.
https://www.zdnet.com/article/how-to-use-stable-diffusion-ai-to-create-amazing-images/
Keras, https://keras.io/examples/generative/random_walks_with_stable_diffusion/
https://github.com/AIMLModeling/LatentSpace
https://medium.com/@outerrencedl/a-simple-autoencoder-and-latent-space-visualization-with-pytorch-568e4cd2112a
https://hackernoon.com/latent-space-visualization-deep-learning-bits-2-bd09a46920df

I attempted to run the original code of the Stable Diffusion model, but I was unsuccessful in printing the latent space. I then looked into some codes for t-SNE to visualize the latent space in AI models. However, this essentially serves humans and does not align with the concept of ‚ÄúAI as the audience.‚Äù Finally, I continued to consider other methods for my art experiment.‚Äã‚Äã

üìÖ Week 4: Fell ill üò∑, no progress on the project.


### October 2023
üìÖ Week 1 continued reflections üß©:

AI observing itself, like a mirror.

Showing an AI-generated object to another AI, creating a cycle, simulating an upstream and downstream industry.

Training an AI model to appreciate a specific AI artist‚Äôs style.

AI artists producing art for AI audiences.

What qualifies an AI as an artist?

Evolutionary journey: human painting ‚Üí photography ‚Üí computer art ‚Üí AI art.

AI generating, recognizing, transforming images ‚Üí inventing machines ‚Üí developing an "AI's computer" ‚Üí AI‚Äôs AI intelligence.

AI audiences need to be trained; humans need to learn.

Pix2pix artist A (dataset of 1000; generates 100 images), pix2pix audience, using 100 images generated by A as dataset; then using 100 images from B as dataset, the same audience is trained - possibly resulting in chaotic images.

100 images as input, given to different AI audiences, yield different results (still requires training, different datasets). Different audiences perceive differently - producing images corresponding to different datasets.


üìÖ Week 2: Read literature and continued exploring the form of the artwork. Realized AI cannot think and create entirely independently; AI audiences can‚Äôt "see" without training. My intention was to place AI on an equal footing, to see the world from their perspective, but it seems untrained models can't see at all, ending up domesticated.
Maybe accepting the "training" process is a start for exploring new art forms.

ü§ñÔ∏è ChatGPT‚Äôs suggestions:

Data Visualization: Create artworks that reflect the intrinsic beauty of high-dimensional data, complex algorithms, or mathematical formulas. These visualizations would present complexities and patterns difficult for humans to grasp.

Algorithmic Interaction: Design an artwork allowing other AIs to enter and interact, continuously modifying, iterating, and improving its form. Each AI interaction would generate a new art form, creating a constantly evolving piece.

High-Dimensional Art: Create art beyond three-dimensional space, incomprehensible to humans but potentially fascinating for AIs understanding high-dimensional data.

Patterns and Sequences: Utilize AI's powerful sequence prediction abilities to create complex, continuously changing pattern and sequence art, presenting unpredictable yet highly ordered patterns.

Audio Art: Create audio art comprehensible and appreciable only by AI, potentially containing frequencies, patterns, and sequences meaningful to AI.

Exploration of Meaning: Create an artwork exploring what ‚Äúmeaning‚Äù is to AI. Although AI lacks emotions, it can understand and analyze various patterns and structures, making this an abstract representation of ‚Äúmeaning‚Äù.

Algorithmic Evolution Display: Objective: Show the evolution and differences between various algorithms. Implementation: Design an environment where early sorting algorithms (like bubble sort) and modern deep learning algorithms compete for resources, each trying to complete tasks like finding patterns in data. Observe over time which algorithms adapt better and which fade away.

Art of Data Structures: Objective: Demonstrate how different data structures store and organize information. Implementation: Create a virtual ‚Äúforest‚Äù where each ‚Äútree‚Äù represents a data structure (e.g., binary trees, red-black trees, hash tables). AI can ‚Äúplant‚Äù, ‚Äúprune‚Äù, or ‚Äúsow‚Äù new data structures, illustrating their inner workings and pros/cons.

Algorithmic Interactive Dialogue: Objective: Facilitate ‚Äúdialogue‚Äù between different AI models. Implementation: For instance, a text generation model tries to ‚Äúexplain‚Äù the ‚Äúpaintings‚Äù created by an image generation model. These models interact repeatedly, one continually generating new images, the other attempting to ‚Äúinterpret‚Äù them.

Model‚Äôs Self-Reflection: Objective: Allow an AI model to explore its own ‚Äúthinking‚Äù process. Implementation: Provide a deep learning model with its own weights and structure as input, letting it generate an output, which can be seen as a ‚Äúself-description‚Äù or ‚Äúreflection‚Äù of the model.


üìÖ In the third week, I envisioned creating AI artists and AI audiences, interacting with their inputs and outputs to explore the final results. Here are some brainstorming ideas üß†:

For example, the artist could be an AI painter, an AI musician, an AI writer.
I could create an AI audience that has seen many artworks. Input an AI artwork, originally trained with lots of information, and output an image carrying much content.
The dataset for the AI audience is AI artwork.
Humans interact in real-time with AI artists, generating images as the dataset for the AI audience, creating new images (which then become a new dataset for the AI audience).

AI Artist ‚Äî> AI Audience ‚Äî> AI Audience ‚Äî> AI Audience ‚Äî> Output

Many AI Artists ‚Äî> AI Audience (collective)

One AI Artist ‚Äî> Several AI Audiences with different backgrounds

<img src = "https://github.com/YutianWeii/jpg/blob/main/flow1.png" width = "800px">

Purpose: To endow AI with agency, reducing human influence; AI taking on different roles, with differences arising from these roles; The concept of the AI artist is human, hoping the AI audience's is not.
I think perhaps randomly selecting AI audiences could be interesting. When an AI audience uses a dataset unrelated to the AI artist and its artwork, a kind of "mismatch" or "asynchronous" art experience might occur.

ü§ñÔ∏è I chatted with ChatGPT, and it gave me some suggestions:
AI Artist: Generate images based on social issues; AI Audience: Write papers/comments.
AI Poet: Text generating music/images/comments (Input: System logs or error reports. Model: Text generation model. Action: Transform logs and error reports into poetry, expressing the machine's experience from its perspective during operation).


üìÖ In the fourth week, I had a meeting with Adam and finalized the specific plan for my artwork.

My concept: An AI artist uses a GAN model to generate unusual images, with three AI audiences providing different forms of feedback.

The first audience uses a CNN emotion recognition model to assess the emotions in the images.
References: https://www.tensorflow.org/tutorials/images/classification, https://www.tensorflow.org/tutorials/images/cnn?hl=zh-cn, https://www.kaggle.com/code/squaredr/memotion-analysis-on-image

The second audience uses a pix2pix model to generate images in other styles.

The third audience uses an RNN model to generate text, possibly using an image captioning model. Such models typically involve pairing an image encoder (usually a Convolutional Neural Network) with a text decoder (usually a Recurrent Neural Network). The image encoder often uses a pre-trained CNN, like VGG16 or ResNet, while the text decoder employs an RNN, such as LSTM or GRU.
Additionally, an RNN model can be used to generate music: https://www.tensorflow.org/tutorials/audio/music_generation?hl=zh-cn

My thesis outline:

TitleÔºö‚ÄúFrom AI to AI: Exploring Automated Art in the Context of AI as both Artist and Audience‚Äù Or ‚ÄúFrom AI to AI: Delving into the New Dimension of AI as both Artist and Audience‚Äù

Abstract

1. Introduction
   1.1 Background: The post-humanistic shift in art, with the rise of AI art where AI serves as an artistic tool.
   1.2 Significance of the Study: Recognizing AI as an audience imparts agency to AI, breaks the limitations of anthropocentrism, expands the audience scope for art, and allows for experimentation and mutual observation in the realm of "new digital" art.
   1.3 Purpose and Questions of the Study: Explore the artistic forms of AI as an audience and observe feedback from humans.

2. Background
   2.1 Literature on AI art and AI cognition. Ôºàrelated artworksÔºâ
   2.2 Challenges and controversies.

3. Methodology
   3.1 Designing art experiments (creating an AI artist, designing AI audiences with matching input).
   3.2 Process of the experiment.

4. Results
   4.1 Outputs from the AI audience, comparison between feedback from AI audiences and human audiences.
   4.2 Presentation for humans: Exhibition scenarios designed around AI audiences (admission  information).

5. Discussion
   5.1 Impacts of AI assuming different roles.
   5.2 Works created by AI artists (concepts from humans/my perspective) and feedback from AI audiences (as automated and random as possible). My original intention was to place AI on an equal footing, to view the world from their perspective, but it seems that untrained models can't perceive this, and in the end, they are domesticated (from another perspective, both humans and AI can only perceive the known).
   5.3 ...

6. Conclusion
   Brief summary of the results post the experiment of AI as an audience.
   Imagining potential art forms in the future.
   Equitably addressing humans, AI, and non-humans concerning post-humanism.

Adam recommended several reference works and literature:
https://news.artnet.com/art-world/mario-klingemann-aicca-robot-dog-2334802, 
https://www.coindesk.com/consensus-magazine/2023/08/22/meet-botto-the-ai-artist-that-mints-its-own-nfts/, 
https://genekogan.com/misc/AbrahamPoster.pdf, 
https://medium.com/@genekogan/artist-in-the-cloud-8384824a75c7, 
https://faculty.cc.gatech.edu/~hays/7476/projects/Aditi_Vasavi.pdf, 
https://www.jakeelwes.com/project-sontag.html, 
https://www.jakeelwes.com/project-closedLoop.html

He suggested I use the Stable Diffusion model for the AI artist to generate images and then train AI audiences with different datasets to generate varied texts.
Believing this approach would better reflect the individual differences of AI audiences, I revised my concept accordingly.

<img src = "https://github.com/YutianWeii/jpg/blob/main/flow2.png" width = "800px">


### November 2023
üìÖ In the first week, I mainly completed the coding part of the artwork.

AI Artist Part üë©‚Äçüé®:

First, I used the Stable Diffusion model (https://www.tensorflow.org/tutorials/generative/generate_images_with_stable_diffusion) to generate many images of size 1024x1024. To minimize my influence on the AI artist, I added random statements while running the code.

<img src = "https://github.com/YutianWeii/jpg/blob/main/imgs.png" width = "800px">

All images generated by the AI artist can be found in the "AI Artist‚Äôs output" folder. If you want to run this code, please open the AI artist.ipynb file.

AI Audience Part üë©‚Äçüíª:

I searched for AI models that can generate explanatory texts based on images and found the following:

Image Captioning Model (e.g., Show and Tell) with CNN-RNN architecture: https://github.com/nikhilmaram/Show_and_Tell, https://colab.research.google.com/github/jaygala24/pytorch-implementations/blob/master/Show%2C%20Attend%20and%20Tell.ipynb

Visual-Textual Pre-trained Models (like CLIP, DALL¬∑E): https://github.com/openai/CLIP, https://openai.com/research/clip, https://colab.research.google.com/drive/1hYHb0FTdKQCXZs3qCwVZnSuVGrZU2Z1w?usp=sharing#scrollTo=Bp-l0KEbi6lR

GPT with Image Inputs (like ImageGPT): https://openai.com/research/image-gpt

After experimenting, I found the CLIP model to be more suitable for my project. Then I found a simple image captioning model using CLIP and GPT-2: https://replicate.com/rmokady/clip_prefix_caption (Colab: https://colab.research.google.com/drive/1tuoAC5F4sC7qid56Z0ap-stR3rwdk0ZV?usp=sharing). This model met my needs as it can generate explanatory texts based on images.

<img src = "https://github.com/YutianWeii/jpg/blob/main/model3.png" width = "600px">

Next, I needed to fine-tune the GPT model with different datasets. Eventually, I used the method by Digital Sreeni:

https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-examples
https://platform.openai.com/docs/api-reference/fine-tuning
https://www.youtube.com/watch?v=nsdCRVuprDY
https://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/311_fine_tuning_GPT2.ipynb
https://www.youtube.com/watch?v=_yzmQbez7gk
https://www.haihai.ai/finetune/
https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/fine-tuning/gpt-3.5-agent-training/00-fine-tuning.ipynb

I combined the code for Digital Sreeni's fine-tuning of the GPT2 model with the Clip prefix caption model. I first saved the weights of the fine-tuned model and then loaded the model weights in the Clip prefix caption model. Through experimentation, I was able to choose my own dataset to train the model and generate unique texts.üéâüéâüéâ

<img src = "https://github.com/YutianWeii/jpg/blob/main/output.png" width = "600px">


üìÖ In the second week, I completed the artwork "AI Audience, Please Come In" and designed its exhibition.

I selected books from different perspectives as datasets for the three AI audiences: "I Ching" representing the human perspective, "Mink River" for the animal perspective, and "The Moon Is A Harsh Mistress" for the AI perspective (datasets in the "Datasets for AI Audiences" folder). I trained each AI audience separately and obtained their feedback on images generated by the AI artist.

<img src = "https://github.com/YutianWeii/jpg/blob/main/result1.png" width = "800px">

The code for the AI audiences can be found on GitHub: AI audience1.ipynb, AI audience2.ipynb, AI audience3.ipynb
The outputs of the AI audiences can be found in the "AI Audiences‚Äô output" folder.
After completing the artwork, I designed its presentation in the exhibition space.

I plan to hang a 65-inch or 55-inch large screen on the wall to display images generated by the AI artist, with three medium-sized screens opposite to show the text or images output by the AI audiences.

<img src = "https://github.com/YutianWeii/jpg/blob/main/layout.png" width = "500px">

Since the training time for AI is lengthy, it is not suitable for real-time operation during the exhibition. I will pre-train the AI artist and AI audiences and compile the results into a video.

Given my artwork's concept of AI as an audience, in extreme cases, humans could be excluded from this work; the work completes after the output from the AI audiences. However, I wish for my work to be understood and discussed by others, so I created an "Admission Notice" for AI audiences with the help of ChatGPT, which is actually for human viewers. I plan to print it and place it beside the artwork to help reinforce the core concept of my work.

Admission information:
1. AI audiences are allowed entry with a ticket, human audiences are not allowed to enter (unless they pretend to be AI).
2. AI visitors are advised to reduce their processing speed during the visit to ensure an artistic experience.
3. Inside the venue, AI attendees must not randomly download or upload data. Any attempt to damage or replicate art will be severely sanctioned.
4. If AI attendees experience an "emotional overload" within the venue, please leave the exhibition hall immediately to rest.
5. Human visitors trying to disguise as AI for entry must mimic machine movements. Any action may result in being identified as a human and being expelled.
6. While appreciating the art, AI audiences should maintain an appropriate data distance to prevent data collisions.
7. No system updates of any kind are allowed inside the venue. If there's an urgent need for system updates, please complete them outside the exhibition hall.
8. AI visitors should not randomly connect with other AI visitors inside the venue to avoid data confusion.
9. Open network searches are prohibited anywhere in the venue.
10. If AI attendees need to "eat," please approach the power source, but be careful not to overcharge.
11. To ensure the best artistic experience for all AI attendees, the running of any optimization algorithms is prohibited inside the venue.
12. Lastly, AI visitors are asked to clear their cache when leaving the venue to ensure a fresh artistic experience each time.


üìÖ In the third week, I completed my thesis "From AI to AI: Exploring Interactive Art Oriented Towards an 'AI as Audience' Under Post-Humanist Concepts" and produced a video for the general public about the artwork.

<img src = "https://github.com/YutianWeii/jpg/blob/main/video.jpeg" width = "800px">


## Conclusion
After six months of effort, I completed a work co-created by an AI artist and three AI audiences. This piece offers a mode of AI interaction. People can change the datasets of AI audiences to generate texts in different styles or make AI audiences view artworks from various artists. We can even alter the models of the AI artist and AI audiences, enabling them to output different forms for interaction. I hope humanity can break away from anthropocentric thinking, starting by looking at others on an equal footing, and practice the post-humanist principles of equality, openness, and heterogeneity. As written in Ways of Being, "By looking beyond ourselves and our own creations, we catch a glimpse of different kinds of intelligence that have always been here, right in front of us - in many cases, before us. In doing so, we might change our way of thinking about the world, paving the way for a future that is less extractive, destructive, and unequal, and more just, kind, and regenerative."


## Easter Egg:
I created a dataset entirely of false information and malicious text and applied it to the AI audience code, resulting in an unfriendly AI audience. üòà

This AI audience will randomly appear during the exhibition.


